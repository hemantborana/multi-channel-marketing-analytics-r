cat("- Strong correlation (0.91) between duration and total revenue\n")
cat("- Retention is more valuable than acquisition\n")
cat("- RECOMMENDATION: Focus on long-term retention strategies\n\n")
cat("INSIGHT 7: Support Issues Signal Risk\n")
cat("- Average support tickets: 0.87 per customer\n")
cat("- High ticket volume may indicate dissatisfaction\n")
cat("- RECOMMENDATION: Proactive support outreach for multi-ticket customers\n\n")
cat(rep("=", 70), "\n", sep="")
cat("Analysis complete.\n")
cat(rep("=", 70), "\n\n", sep="")
---
title: "Streaming Service Customer Behavior Analysis"
# ETL Pipeline for Multi-Source Marketing Data
library(jsonlite)
library(XML)
library(dplyr)
library(tidyr)
library(lubridate)
setwd("C:/Users/User/projects/S5/dmv-m8/Generated_data")
cat("starting ETL pipeline...\n\n")
# EXTRACT phase - load all raw data
cat("extracting data from sources...\n")
# source 1: CSV
campaigns_raw <- read.csv("Digital_Campaigns.csv", stringsAsFactors = FALSE)
# source 2: JSON
social_raw <- fromJSON("Social_Engagement.json", simplifyDataFrame = TRUE)
# source 3: XML
xml_doc <- xmlParse("Web_Analytics.xml")
xml_root <- xmlRoot(xml_doc)
web_sessions <- xmlApply(xml_root, function(x) {
data.frame(
session_id = xmlValue(x[["session_id"]]),
date = xmlValue(x[["date"]]),
source = xmlValue(x[["source"]]),
medium = xmlValue(x[["medium"]]),
campaign = xmlValue(x[["campaign"]]),
pageviews = as.numeric(xmlValue(x[["pageviews"]])),
duration = as.numeric(xmlValue(x[["duration_seconds"]])),
bounce = xmlValue(x[["bounce"]]),
transactions = as.numeric(xmlValue(x[["transactions"]])),
revenue = as.numeric(xmlValue(x[["revenue"]])),
device = xmlValue(x[["device"]]),
stringsAsFactors = FALSE
)
})
web_raw <- do.call(rbind, web_sessions)
# source 4: TXT
journey_raw <- readLines("Customer_Journey.txt")
journey_lines <- journey_raw[journey_raw != ""]
cat("extraction complete\n\n")
# TRANSFORM phase - clean and standardize
cat("transforming data...\n")
campaigns_clean <- campaigns_raw %>%
mutate(
start_date = as.Date(start_date),
end_date = as.Date(end_date),
campaign_duration = as.numeric(end_date - start_date)
)
campaigns_clean <- campaigns_clean %>%
mutate(
cost_per_conversion = round(budget / conversions, 2),
revenue_per_conversion = round(revenue / conversions, 2)
)
cat("campaigns data cleaned:", nrow(campaigns_clean), "records\n")
# transform social data
social_clean <- social_raw %>%
mutate(
post_date = as.POSIXct(post_date, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC"),
post_date_only = as.Date(post_date),
saves = ifelse(is.na(saves), 0, saves),
total_engagement = likes + comments + shares + saves
)
social_clean <- social_clean %>%
left_join(campaigns_clean %>% select(campaign_id, channel), by = "campaign_id")
cat("social data cleaned:", nrow(social_clean), "records\n")
# transform web analytics
web_clean <- web_raw %>%
mutate(
date = as.Date(date),
bounce = as.logical(ifelse(bounce == "true", TRUE, FALSE)),
# standardize campaign names
campaign = ifelse(campaign == "none", NA, campaign),
duration_minutes = round(duration / 60, 2)
)
# classify traffic type
web_clean <- web_clean %>%
mutate(
traffic_type = case_when(
source %in% c("Direct", "Organic") ~ "Organic",
source %in% c("Email") ~ "Email",
source %in% c("Facebook", "Instagram", "Twitter", "LinkedIn") ~ "Social",
source %in% c("Google Ads") ~ "Paid Search",
source %in% c("Display", "YouTube") ~ "Display/Video",
TRUE ~ "Other"
)
)
cat("web analytics cleaned:", nrow(web_clean), "records\n")
parse_journey <- function(line) {
parts <- strsplit(line, " \\| ")[[1]]
if(length(parts) >= 4) {
timestamp_parts <- strsplit(parts[1], " ")[[1]]
date_parts <- strsplit(timestamp_parts[1], "-")[[1]]
correct_date <- paste0("2024-", date_parts[2], "-", date_parts[3])
correct_timestamp <- paste(correct_date, timestamp_parts[2])
return(data.frame(
timestamp = correct_timestamp,
user_id = parts[2],
event_type = parts[3],
campaign_id = parts[4],
details = ifelse(length(parts) > 4, parts[5], ""),
stringsAsFactors = FALSE
))
}
return(NULL)
}
journey_parsed <- do.call(rbind, lapply(journey_lines, parse_journey))
journey_clean <- journey_parsed %>%
mutate(
timestamp = as.POSIXct(timestamp, format = "%Y-%m-%d %H:%M:%S"),
date = as.Date(timestamp),
campaign_id = ifelse(campaign_id == "none", NA, campaign_id)
)
# extract order values from purchase events
journey_clean <- journey_clean %>%
mutate(
order_value = ifelse(
event_type == "PURCHASE",
as.numeric(gsub(".*order_value=([0-9.]+).*", "\\1", details)),
NA
),
cart_value = ifelse(
event_type == "CART_ABANDON",
as.numeric(gsub(".*cart_value=([0-9.]+).*", "\\1", details)),
NA
)
)
cat("customer journey cleaned:", nrow(journey_clean), "records\n")
cat("\ntransformation complete\n\n")
# LOAD phase - create integrated datasets
cat("creating integrated datasets...\n")
# dataset 1: campaign performance with social engagement
campaign_social <- campaigns_clean %>%
left_join(
social_clean %>%
group_by(campaign_id) %>%
summarise(
total_posts = n(),
total_social_likes = sum(likes),
total_social_comments = sum(comments),
total_social_shares = sum(shares),
total_social_clicks = sum(clicks),
avg_engagement_rate = mean(engagement_rate)
),
by = "campaign_id"
) %>%
mutate(
total_posts = ifelse(is.na(total_posts), 0, total_posts),
total_social_likes = ifelse(is.na(total_social_likes), 0, total_social_likes)
)
cat("campaign + social integration:", nrow(campaign_social), "campaigns\n")
# dataset 2: web traffic by campaign
web_by_campaign <- web_clean %>%
filter(!is.na(campaign)) %>%
group_by(campaign) %>%
summarise(
total_sessions = n(),
total_pageviews = sum(pageviews),
avg_duration = mean(duration_minutes),
bounce_rate = mean(bounce) * 100,
web_transactions = sum(transactions),
web_revenue = sum(revenue),
mobile_sessions = sum(device == "mobile"),
desktop_sessions = sum(device == "desktop")
)
campaign_web <- campaign_social %>%
left_join(web_by_campaign, by = c("campaign_id" = "campaign"))
cat("campaign + web integration:", nrow(campaign_web), "campaigns\n")
journey_by_campaign <- journey_clean %>%
filter(!is.na(campaign_id)) %>%
group_by(campaign_id) %>%
summarise(
touchpoints = n(),
unique_users = n_distinct(user_id),
ad_impressions = sum(event_type == "AD_IMPRESSION"),
ad_clicks = sum(event_type == "AD_CLICK"),
site_visits = sum(event_type == "SITE_VISIT"),
purchases = sum(event_type == "PURCHASE"),
cart_abandons = sum(event_type == "CART_ABANDON"),
journey_revenue = sum(order_value, na.rm = TRUE)
)
# final integrated dataset
integrated_data <- campaign_web %>%
left_join(journey_by_campaign, by = "campaign_id")
cat("final integrated dataset:", nrow(integrated_data), "campaigns\n")
# dataset 4: user-level journey analysis
user_journeys <- journey_clean %>%
arrange(user_id, timestamp) %>%
group_by(user_id) %>%
summarise(
first_touch = min(timestamp),
last_touch = max(timestamp),
journey_length_days = as.numeric(difftime(max(timestamp), min(timestamp), units = "days")),
total_touchpoints = n(),
first_campaign = first(campaign_id[!is.na(campaign_id)]),
last_campaign = last(campaign_id[!is.na(campaign_id)]),
converted = any(event_type == "PURCHASE"),
conversion_value = sum(order_value, na.rm = TRUE),
abandoned_cart = any(event_type == "CART_ABANDON")
)
cat("user journey analysis:", nrow(user_journeys), "users\n")
cat("\nintegration complete\n\n")
# data quality validation
cat("data quality checks:\n")
cat("- campaigns with complete data:",
sum(!is.na(integrated_data$total_sessions)), "out of", nrow(integrated_data), "\n")
cat("- users with purchases:", sum(user_journeys$converted), "out of", nrow(user_journeys), "\n")
cat("- total revenue across sources:",
round(sum(campaigns_clean$revenue), 2), "(campaigns),",
round(sum(web_clean$revenue), 2), "(web),",
round(sum(journey_clean$order_value, na.rm = TRUE), 2), "(journey)\n")
# save cleaned datasets
write.csv(campaigns_clean, "campaigns_cleaned.csv", row.names = FALSE)
write.csv(social_clean, "social_cleaned.csv", row.names = FALSE)
write.csv(web_clean, "web_cleaned.csv", row.names = FALSE)
write.csv(journey_clean, "journey_cleaned.csv", row.names = FALSE)
write.csv(integrated_data, "integrated_data.csv", row.names = FALSE)
write.csv(user_journeys, "user_journeys.csv", row.names = FALSE)
cat("\ncleaned datasets saved\n")
# advanced analytics and attribution modeling
library(dplyr)
library(tidyr)
setwd("C:/Users/User/projects/S5/dmv-m8/Generated_data")
cat("loading cleaned data...\n")
integrated <- read.csv("integrated_data.csv", stringsAsFactors = FALSE)
user_journeys <- read.csv("user_journeys.csv", stringsAsFactors = FALSE)
journey_clean <- read.csv("journey_cleaned.csv", stringsAsFactors = FALSE)
campaigns <- read.csv("campaigns_cleaned.csv", stringsAsFactors = FALSE)
cat("data loaded\n\n")
# 1. MULTI-CHANNEL ATTRIBUTION ANALYSIS
cat("--- Multi-Channel Attribution Analysis ---\n\n")
# simple attribution models
first_touch <- user_journeys %>%
filter(converted == TRUE) %>%
group_by(first_campaign) %>%
summarise(
conversions = n(),
revenue = sum(conversion_value)
) %>%
rename(campaign_id = first_campaign) %>%
mutate(model = "First Touch")
cat("First Touch Attribution:\n")
print(first_touch)
cat("\n")
last_touch <- user_journeys %>%
filter(converted == TRUE) %>%
group_by(last_campaign) %>%
summarise(
conversions = n(),
revenue = sum(conversion_value)
) %>%
rename(campaign_id = last_campaign) %>%
mutate(model = "Last Touch")
cat("Last Touch Attribution:\n")
print(last_touch)
cat("\n")
# linear attribution - equal credit to all touchpoints
journey_data <- journey_clean %>%
filter(!is.na(campaign_id))
linear_attribution <- journey_data %>%
inner_join(user_journeys %>% select(user_id, converted, conversion_value),
by = "user_id") %>%
filter(converted == TRUE) %>%
group_by(user_id) %>%
mutate(
touchpoint_count = n(),
attributed_value = conversion_value / touchpoint_count
) %>%
ungroup() %>%
group_by(campaign_id) %>%
summarise(
conversions = n_distinct(user_id),
attributed_revenue = sum(attributed_value)
) %>%
mutate(model = "Linear")
cat("Linear Attribution (equal credit):\n")
print(linear_attribution)
cat("\n")
time_decay <- journey_data %>%
inner_join(user_journeys %>% select(user_id, converted, conversion_value, last_touch),
by = "user_id") %>%
filter(converted == TRUE) %>%
mutate(
timestamp = as.POSIXct(timestamp),
last_touch = as.POSIXct(last_touch),
days_before_conversion = as.numeric(difftime(last_touch, timestamp, units = "days"))
) %>%
group_by(user_id) %>%
mutate(
weight = exp(-days_before_conversion / 7),
total_weight = sum(weight),
attributed_value = (weight / total_weight) * conversion_value
) %>%
ungroup() %>%
group_by(campaign_id) %>%
summarise(
attributed_revenue = sum(attributed_value),
conversions = n_distinct(user_id)
) %>%
mutate(model = "Time Decay")
cat("Time Decay Attribution (recent touchpoints weighted higher):\n")
print(time_decay)
cat("\n")
# combine all attribution models for comparison
all_attributions <- bind_rows(
first_touch %>% select(campaign_id, model, revenue),
last_touch %>% select(campaign_id, model, revenue),
linear_attribution %>% select(campaign_id, model, attributed_revenue) %>%
rename(revenue = attributed_revenue),
time_decay %>% select(campaign_id, model, attributed_revenue) %>%
rename(revenue = attributed_revenue)
)
# reshape for comparison
attribution_comparison <- all_attributions %>%
pivot_wider(names_from = model, values_from = revenue, values_fill = 0)
cat("Attribution Model Comparison by Campaign:\n")
print(attribution_comparison)
cat("\n\n")
cat("--- Customer Journey Analysis ---\n\n")
journey_stats <- user_journeys %>%
summarise(
avg_touchpoints = mean(total_touchpoints),
avg_journey_days = mean(journey_length_days),
conversion_rate = mean(converted) * 100,
avg_converter_touchpoints = mean(total_touchpoints[converted == TRUE]),
avg_nonconverter_touchpoints = mean(total_touchpoints[converted == FALSE])
)
cat("Journey Statistics:\n")
cat("Average touchpoints per user:", round(journey_stats$avg_touchpoints, 2), "\n")
cat("Average journey length:", round(journey_stats$avg_journey_days, 2), "days\n")
cat("Conversion rate:", round(journey_stats$conversion_rate, 2), "%\n")
cat("Converters avg touchpoints:", round(journey_stats$avg_converter_touchpoints, 2), "\n")
cat("Non-converters avg touchpoints:", round(journey_stats$avg_nonconverter_touchpoints, 2), "\n\n")
# event sequence analysis
event_sequences <- journey_clean %>%
arrange(user_id, timestamp) %>%
group_by(user_id) %>%
summarise(
sequence = paste(event_type, collapse = " -> ")
) %>%
inner_join(user_journeys %>% select(user_id, converted), by = "user_id")
cat("Sample customer journeys:\n")
print(head(event_sequences %>% filter(converted == TRUE), 3))
cat("\n")
# common path analysis
conversion_paths <- journey_clean %>%
inner_join(user_journeys %>% select(user_id, converted), by = "user_id") %>%
filter(converted == TRUE) %>%
count(event_type) %>%
arrange(desc(n))
cat("Events in conversion paths:\n")
print(conversion_paths)
cat("\n")
# touchpoint effectiveness
touchpoint_analysis <- journey_clean %>%
inner_join(user_journeys %>% select(user_id, converted), by = "user_id") %>%
group_by(event_type) %>%
summarise(
total_occurrences = n(),
in_conversion_paths = sum(converted),
conversion_rate = mean(converted) * 100
) %>%
arrange(desc(conversion_rate))
cat("Touchpoint Effectiveness:\n")
print(touchpoint_analysis)
cat("\n\n")
cat("--- Statistical Analysis ---\n\n")
# campaign performance correlation analysis
performance_data <- integrated %>%
select(campaign_id, budget, impressions, clicks, conversions, revenue,
ctr, conversion_rate, total_posts, avg_engagement_rate,
total_sessions, bounce_rate, touchpoints) %>%
filter(!is.na(total_sessions))
# correlation with revenue
correlations <- cor(performance_data %>% select(-campaign_id),
use = "pairwise.complete.obs")
revenue_cors <- correlations[, "revenue"]
revenue_cors <- sort(revenue_cors[names(revenue_cors) != "revenue"], decreasing = TRUE)
cat("Correlation with Revenue (strongest predictors):\n")
print(head(revenue_cors, 5))
cat("\n")
# linear regression model - predicting revenue
revenue_model <- lm(revenue ~ budget + clicks + conversion_rate +
total_posts + total_sessions,
data = performance_data)
cat("Revenue Prediction Model:\n")
print(summary(revenue_model))
cat("\n")
# channel performance analysis
channel_performance <- campaigns %>%
group_by(channel) %>%
summarise(
campaigns = n(),
total_budget = sum(budget),
total_revenue = sum(revenue),
avg_roas = mean(roas),
avg_ctr = mean(ctr),
avg_conversion_rate = mean(conversion_rate),
total_conversions = sum(conversions)
) %>%
arrange(desc(avg_roas))
cat("Channel Performance Summary:\n")
print(channel_performance)
cat("\n")
# efficiency analysis - which campaigns overperform/underperform
campaigns_efficiency <- campaigns %>%
mutate(
expected_conversions = median(conversions),
efficiency = (conversions / expected_conversions) * 100,
status = case_when(
efficiency >= 120 ~ "Overperforming",
efficiency <= 80 ~ "Underperforming",
TRUE ~ "Normal"
)
) %>%
select(campaign_id, campaign_name, channel, conversions, efficiency, status, roas)
cat("Campaign Efficiency Analysis:\n")
print(campaigns_efficiency)
cat("\n")
# cart abandonment analysis
abandonment_rate <- mean(user_journeys$abandoned_cart) * 100
potential_revenue <- sum(journey_clean$cart_value, na.rm = TRUE)
cat("Cart Abandonment Insights:\n")
cat("Abandonment rate:", round(abandonment_rate, 2), "%\n")
cat("Potential lost revenue:", round(potential_revenue, 2), "\n")
cat("Recovery opportunity:", round(potential_revenue * 0.15, 2),
"(assuming 15% recovery rate)\n\n")
# save analytics results
write.csv(attribution_comparison, "attribution_analysis.csv", row.names = FALSE)
write.csv(channel_performance, "channel_performance.csv", row.names = FALSE)
write.csv(campaigns_efficiency, "campaign_efficiency.csv", row.names = FALSE)
cat("analytics results saved\n")
cat("advanced analytics complete!\n")
# comprehensive visualization suite
library(ggplot2)
library(plotly)
library(ggplot2)
library(plotly)
# comprehensive visualization suite
setwd("C:/Users/User/projects/S5/dmv-m8/Generated_data")
viz_folder <- "C:/Users/User/projects/S5/dmv-m8/Visualizations"
if (!dir.exists(viz_folder)) {
dir.create(viz_folder)
}
cat("loading data for visualizations...\n")
campaigns <- read.csv("campaigns_cleaned.csv", stringsAsFactors = FALSE)
integrated <- read.csv("integrated_data.csv", stringsAsFactors = FALSE)
channel_perf <- read.csv("channel_performance.csv", stringsAsFactors = FALSE)
attribution <- read.csv("attribution_analysis.csv", stringsAsFactors = FALSE)
user_journeys <- read.csv("user_journeys.csv", stringsAsFactors = FALSE)
journey_clean <- read.csv("journey_cleaned.csv", stringsAsFactors = FALSE)
cat("creating visualizations...\n\n")
# viz 1: channel performance comparison
cat("creating viz 1: channel performance...\n")
channel_long <- channel_perf %>%
select(channel, avg_roas, avg_ctr, avg_conversion_rate) %>%
pivot_longer(cols = -channel, names_to = "metric", values_to = "value") %>%
mutate(
metric = case_when(
metric == "avg_roas" ~ "ROAS",
metric == "avg_ctr" ~ "CTR (%)",
metric == "avg_conversion_rate" ~ "Conv Rate (%)"
)
)
p1 <- ggplot(channel_long, aes(x = reorder(channel, -value), y = value, fill = metric)) +
geom_bar(stat = "identity", position = "dodge", width = 0.7) +
facet_wrap(~metric, scales = "free_y", ncol = 3) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(face = "bold", size = 14),
strip.text = element_text(face = "bold")
) +
labs(
title = "Channel Performance Metrics Comparison",
x = "Channel",
y = "Value",
fill = "Metric"
) +
scale_fill_brewer(palette = "Set2")
ggsave(file.path(viz_folder, "viz1_channel_performance.png"), p1, width = 12, height = 6, dpi = 300)
cat("saved viz1_channel_performance.png\n")
# viz 2: campaign roas vs budget
cat("creating viz 2: roas vs budget scatter...\n")
p2 <- plot_ly(campaigns,
x = ~budget,
y = ~roas,
type = 'scatter',
mode = 'markers',
marker = list(size = ~conversions/5,
color = ~conversions,
colorscale = 'Viridis',
showscale = TRUE,
colorbar = list(title = "Conversions")),
text = ~paste("Campaign:", campaign_name,
"<br>Budget: $", budget,
"<br>ROAS:", round(roas, 2),
"<br>Conversions:", conversions),
hoverinfo = 'text') %>%
layout(title = "Campaign ROAS vs Budget (size = conversions)",
xaxis = list(title = "Budget ($)"),
yaxis = list(title = "ROAS"),
hovermode = 'closest')
